{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from cassandra.util import datetime_from_uuid1\n",
    "from cassandra.cqltypes import TimeUUIDType\n",
    "import uuid \n",
    "import time\n",
    "from uuid import UUID\n",
    "import time_uuid \n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import StringType\n",
    "from pyspark.sql.functions import udf, col\n",
    "import pyspark.sql.functions as sf\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":: loading settings :: url = jar:file:/opt/spark/jars/ivy-2.5.1.jar!/org/apache/ivy/core/settings/ivysettings.xml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ivy Default Cache set to: /home/hien2706/.ivy2/cache\n",
      "The jars for the packages stored in: /home/hien2706/.ivy2/jars\n",
      "mysql#mysql-connector-java added as a dependency\n",
      "com.datastax.spark#spark-cassandra-connector_2.12 added as a dependency\n",
      ":: resolving dependencies :: org.apache.spark#spark-submit-parent-f053457f-26f9-4cf6-8bbf-058b5fb01a67;1.0\n",
      "\tconfs: [default]\n",
      "\tfound mysql#mysql-connector-java;8.0.32 in central\n",
      "\tfound com.mysql#mysql-connector-j;8.0.32 in central\n",
      "\tfound com.google.protobuf#protobuf-java;3.21.9 in central\n",
      "\tfound com.datastax.spark#spark-cassandra-connector_2.12;3.1.0 in central\n",
      "\tfound com.datastax.spark#spark-cassandra-connector-driver_2.12;3.1.0 in central\n",
      "\tfound com.datastax.oss#java-driver-core-shaded;4.12.0 in central\n",
      "\tfound com.datastax.oss#native-protocol;1.5.0 in central\n",
      "\tfound com.datastax.oss#java-driver-shaded-guava;25.1-jre-graal-sub-1 in central\n",
      "\tfound com.typesafe#config;1.4.1 in central\n",
      "\tfound org.slf4j#slf4j-api;1.7.26 in central\n",
      "\tfound io.dropwizard.metrics#metrics-core;4.1.18 in central\n",
      "\tfound org.hdrhistogram#HdrHistogram;2.1.12 in central\n",
      "\tfound org.reactivestreams#reactive-streams;1.0.3 in central\n",
      "\tfound com.github.stephenc.jcip#jcip-annotations;1.0-1 in central\n",
      "\tfound com.github.spotbugs#spotbugs-annotations;3.1.12 in central\n",
      "\tfound com.google.code.findbugs#jsr305;3.0.2 in central\n",
      "\tfound com.datastax.oss#java-driver-mapper-runtime;4.12.0 in central\n",
      "\tfound com.datastax.oss#java-driver-query-builder;4.12.0 in central\n",
      "\tfound org.apache.commons#commons-lang3;3.10 in central\n",
      "\tfound com.thoughtworks.paranamer#paranamer;2.8 in central\n",
      "\tfound org.scala-lang#scala-reflect;2.12.11 in central\n",
      ":: resolution report :: resolve 432ms :: artifacts dl 17ms\n",
      "\t:: modules in use:\n",
      "\tcom.datastax.oss#java-driver-core-shaded;4.12.0 from central in [default]\n",
      "\tcom.datastax.oss#java-driver-mapper-runtime;4.12.0 from central in [default]\n",
      "\tcom.datastax.oss#java-driver-query-builder;4.12.0 from central in [default]\n",
      "\tcom.datastax.oss#java-driver-shaded-guava;25.1-jre-graal-sub-1 from central in [default]\n",
      "\tcom.datastax.oss#native-protocol;1.5.0 from central in [default]\n",
      "\tcom.datastax.spark#spark-cassandra-connector-driver_2.12;3.1.0 from central in [default]\n",
      "\tcom.datastax.spark#spark-cassandra-connector_2.12;3.1.0 from central in [default]\n",
      "\tcom.github.spotbugs#spotbugs-annotations;3.1.12 from central in [default]\n",
      "\tcom.github.stephenc.jcip#jcip-annotations;1.0-1 from central in [default]\n",
      "\tcom.google.code.findbugs#jsr305;3.0.2 from central in [default]\n",
      "\tcom.google.protobuf#protobuf-java;3.21.9 from central in [default]\n",
      "\tcom.mysql#mysql-connector-j;8.0.32 from central in [default]\n",
      "\tcom.thoughtworks.paranamer#paranamer;2.8 from central in [default]\n",
      "\tcom.typesafe#config;1.4.1 from central in [default]\n",
      "\tio.dropwizard.metrics#metrics-core;4.1.18 from central in [default]\n",
      "\tmysql#mysql-connector-java;8.0.32 from central in [default]\n",
      "\torg.apache.commons#commons-lang3;3.10 from central in [default]\n",
      "\torg.hdrhistogram#HdrHistogram;2.1.12 from central in [default]\n",
      "\torg.reactivestreams#reactive-streams;1.0.3 from central in [default]\n",
      "\torg.scala-lang#scala-reflect;2.12.11 from central in [default]\n",
      "\torg.slf4j#slf4j-api;1.7.26 from central in [default]\n",
      "\t---------------------------------------------------------------------\n",
      "\t|                  |            modules            ||   artifacts   |\n",
      "\t|       conf       | number| search|dwnlded|evicted|| number|dwnlded|\n",
      "\t---------------------------------------------------------------------\n",
      "\t|      default     |   21  |   0   |   0   |   0   ||   20  |   0   |\n",
      "\t---------------------------------------------------------------------\n",
      ":: retrieving :: org.apache.spark#spark-submit-parent-f053457f-26f9-4cf6-8bbf-058b5fb01a67\n",
      "\tconfs: [default]\n",
      "\t0 artifacts copied, 20 already retrieved (0kB/9ms)\n",
      "24/09/14 16:39:34 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Hien's project\") \\\n",
    "    .config(\"spark.jars.packages\", \"mysql:mysql-connector-java:8.0.32,com.datastax.spark:spark-cassandra-connector_2.12:3.1.0\") \\\n",
    "    .config(\"spark.cassandra.connection.host\", \"localhost\") \\\n",
    "    .config(\"spark.cassandra.connection.port\", \"9042\") \\\n",
    "    .getOrCreate()\n",
    "# 'localhost' if Spark is outside Docker, 'cassandra' if Spark is inside Docker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_click_data(df):\n",
    "    click_data = df.filter(df.custom_track == 'click')\n",
    "    click_data.createOrReplaceTempView('click_data')\n",
    "    return spark.sql(\"\"\"select date(ts) as date,\n",
    "                        hour(ts) as hour ,\n",
    "                        job_id,\n",
    "                        publisher_id,\n",
    "                        campaign_id,\n",
    "                        group_id,\n",
    "                        round(avg(bid),2) as bid_set , \n",
    "                        sum(bid) as spend_hour , \n",
    "                        count(*) as click \n",
    "                        from click_data \n",
    "                        group by date(ts), hour(ts), job_id, publisher_id, campaign_id, group_id\"\"\")\n",
    "    \n",
    "    \n",
    "def process_conversion_data(df):\n",
    "    conversion_data = df.filter(df.custom_track == 'conversion')\n",
    "    conversion_data.createOrReplaceTempView('conversion_data')\n",
    "    return spark.sql(\"\"\"select date(ts) as date,\n",
    "                                hour(ts) as hour ,\n",
    "                                job_id,\n",
    "                                publisher_id,\n",
    "                                campaign_id,\n",
    "                                group_id, \n",
    "                                count(*) as conversion \n",
    "                                from conversion_data \n",
    "                                group by date(ts), hour(ts),job_id,publisher_id,campaign_id,group_id\"\"\")\n",
    "    \n",
    "\n",
    "def process_qualified_data(df):\n",
    "    qualified_data = df.filter(df.custom_track == 'qualified')\n",
    "    qualified_data.createOrReplaceTempView('qualified_data')\n",
    "\n",
    "    return spark.sql(\"\"\"select date(ts) as date,\n",
    "                               hour(ts) as hour,\n",
    "                               job_id,\n",
    "                               publisher_id,\n",
    "                               campaign_id,\n",
    "                               group_id, \n",
    "                               count(*) as qualified \n",
    "                               from qualified_data \n",
    "                               group by date(ts),hour(ts),job_id,publisher_id,campaign_id,group_id\"\"\")\n",
    "    \n",
    "    \n",
    "def process_unqualified_data(df):\n",
    "    unqualified_data = df.filter(df.custom_track == 'unqualified')\n",
    "    unqualified_data.createOrReplaceTempView('unqualified_data')\n",
    "    return spark.sql(\"\"\"select date(ts) as date,\n",
    "                                 hour(ts) as hour ,\n",
    "                                 job_id,\n",
    "                                 publisher_id,\n",
    "                                 campaign_id,\n",
    "                                 group_id, \n",
    "                                 count(*) as unqualified \n",
    "                                 from unqualified_data \n",
    "                                 group by date(ts), hour(ts),job_id,publisher_id,campaign_id,group_id\"\"\")\n",
    "    \n",
    "    \n",
    "def process_cassandra_data(df):\n",
    "    click_data = process_click_data(df)\n",
    "    conversion_data = process_conversion_data(df)\n",
    "    qualified_data = process_qualified_data(df)\n",
    "    unqualified_data = process_unqualified_data(df)\n",
    "    \n",
    "    assert click_data is not None, \"click_data is None\"\n",
    "    assert conversion_data is not None, \"conversion_data is None\"\n",
    "    assert qualified_data is not None, \"qualified_data is None\"\n",
    "    assert unqualified_data is not None, \"unqualified_data is None\"\n",
    "\n",
    "    final = click_data.join(conversion_data, on=['date', 'hour', 'job_id', 'publisher_id', 'campaign_id', 'group_id'], how='full') \\\n",
    "        .join(qualified_data, on=['date', 'hour', 'job_id', 'publisher_id', 'campaign_id', 'group_id'], how='full') \\\n",
    "        .join(unqualified_data, on=['date', 'hour', 'job_id', 'publisher_id', 'campaign_id', 'group_id'], how='full')\n",
    "    return final\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def finalize_data(df,cassandra_latest_time):\n",
    "    df = df.withColumn('updated_at',sf.lit(cassandra_latest_time))\n",
    "    df = df.withColumn('sources',sf.lit('Cassandra'))\n",
    "    df = df.withColumnRenamed('date','dates')\n",
    "    df = df.withColumnRenamed('hour','hours')\n",
    "    df = df.withColumnRenamed('qualified','qualified_application')\n",
    "    df = df.withColumnRenamed('unqualified','disqualified_application')\n",
    "    df = df.withColumnRenamed('unqualified','disqualified_application')\n",
    "    df = df.withColumnRenamed('click','clicks')\n",
    "    \n",
    "    return df.select(\n",
    "    'job_id',\n",
    "    'dates',\n",
    "    'hours',\n",
    "    'disqualified_application',\n",
    "    'qualified_application',\n",
    "    'conversion',\n",
    "    'company_id',\n",
    "    'group_id',\n",
    "    'campaign_id',\n",
    "    'publisher_id',\n",
    "    'bid_set',\n",
    "    'clicks',\n",
    "    'spend_hour',\n",
    "    'sources',\n",
    "    'updated_at')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_data(df,mysql_latest_time):\n",
    "    df = df.select('ts','job_id','custom_track','bid','campaign_id','group_id','publisher_id')\n",
    "    df = df.filter(df.job_id.isNotNull())\n",
    "    df = df.filter(df.ts.isNotNull())\n",
    "    df = df.withColumn(\"ts\", sf.split(col(\"ts\"), \"\\\\.\").getItem(0))\n",
    "    print(\"After Split:\")\n",
    "    df.show(truncate=False)\n",
    "    df = df.withColumn(\"ts\", sf.to_timestamp(col(\"ts\"), \"yyyy-MM-dd HH:mm:ss\"))\n",
    "    df = df.withColumn(\"bid\", col(\"bid\").cast(\"double\"))\n",
    "    print(df.show(truncate=False))\n",
    "    df = df.where(col('ts')> mysql_latest_time)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_from_mysql(host = 'localhost' ,port = '3306', db_name = 'mydatabase',\n",
    "                        driver = \"com.mysql.cj.jdbc.Driver\", user = 'myuser', password = 'mypassword',\n",
    "                        sql_query = '(SELECT id as job_id, company_id FROM job) A'):\n",
    "    \n",
    "    return spark.read.format('jdbc').options(url = f'jdbc:mysql://{host}:{port}/{db_name}' , \n",
    "                                             driver = driver , \n",
    "                                             dbtable = sql_query , \n",
    "                                             user=user , \n",
    "                                             password = password).load()\n",
    "    \n",
    "\n",
    "def write_data_to_mysql(df,host = 'localhost',port = '3306',\n",
    "                        db_name = 'mydatabase', user = 'myuser', table = 'events',\n",
    "                        password = 'mypassword', driver = \"com.mysql.cj.jdbc.Driver\"):\n",
    "    df.write.format(\"jdbc\") \\\n",
    "    .option(\"driver\",driver) \\\n",
    "    .option(\"url\", f\"jdbc:mysql://{host}:{port}/{db_name}\") \\\n",
    "    .option(\"dbtable\", table) \\\n",
    "    .mode(\"append\") \\\n",
    "    .option(\"user\", user) \\\n",
    "    .option(\"password\", password) \\\n",
    "    .save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MySQL Credentials\n",
    "host = 'localhost'\n",
    "port = '3306'\n",
    "db_name = 'mydatabase'\n",
    "user = 'myuser'\n",
    "password = 'mypassword'\n",
    "driver = \"com.mysql.cj.jdbc.Driver\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main_task(cassandra_latest_time,mysql_latest_time):\n",
    "\n",
    "    print(\"Get data from cassandra\")\n",
    "    df = spark.read.format(\"org.apache.spark.sql.cassandra\").options(table = 'tracking',keyspace = 'my_keyspace').load()\n",
    "\n",
    "    print('Filter out the data')\n",
    "    df = filter_data(df,mysql_latest_time)\n",
    "   \n",
    "    print('Process the data')\n",
    "    df = df.cache()\n",
    "    df = process_cassandra_data(df)\n",
    "    \n",
    "    print('get company data from mysql')\n",
    "    jobs = get_data_from_mysql(host = host,port = port,db_name = db_name,user = user,password = password, driver = driver,\n",
    "                               sql_query = '(SELECT id as job_id, company_id FROM job) A')\n",
    "    \n",
    "    print('Merge the data with company data')\n",
    "    df = df.join(jobs,on = 'job_id',how='left')\n",
    "    \n",
    "    print('finalizing the data')\n",
    "    df = finalize_data(df,cassandra_latest_time)\n",
    "    print('final ouput')\n",
    "    print(df.show(truncate=False))\n",
    "    \n",
    "    print('Write the data to mysql')\n",
    "    write_data_to_mysql(df,host,port,db_name,user,password,driver)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/09/14 17:45:37 WARN V2ScanPartitioningAndOrdering: Spark ignores the partitioning CassandraPartitioning. Please use KeyGroupedPartitioning for better performance\n",
      "24/09/14 17:45:37 WARN V2ScanPartitioningAndOrdering: Spark ignores the partitioning CassandraPartitioning. Please use KeyGroupedPartitioning for better performance\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'datetime.datetime'> :  2024-09-14 17:10:48\n",
      "<class 'datetime.datetime'> :  1970-01-01 23:59:59\n",
      "bruh cassandra_latest_time: 2024-09-14 17:10:48 > mysql_latest_time: 1970-01-01 23:59:59\n",
      "Get data from cassandra\n",
      "+------------------------------------+---+----+-----------+----+------------+----+----+----+----+----+--------+----+------+----+------------+----+----+--------------------------+----+----+----+------------+-----------+----------+----------+--------+----+----+\n",
      "|create_time                         |bid|bn  |campaign_id|cd  |custom_track|de  |dl  |dt  |ed  |ev  |group_id|id  |job_id|md  |publisher_id|rl  |sr  |ts                        |tz  |ua  |uid |utm_campaign|utm_content|utm_medium|utm_source|utm_term|v   |vp  |\n",
      "+------------------------------------+---+----+-----------+----+------------+----+----+----+----+----+--------+----+------+----+------------+----+----+--------------------------+----+----+----+------------+-----------+----------+----------+--------+----+----+\n",
      "|0da68e48-72bc-11ef-99f1-bfb67f995b83|0  |NULL|33         |NULL|click       |NULL|NULL|NULL|NULL|NULL|39      |NULL|171   |NULL|31          |NULL|NULL|2024-09-14 17:09:08.021330|NULL|NULL|NULL|NULL        |NULL       |NULL      |NULL      |NULL    |NULL|NULL|\n",
      "|01a97754-72bc-11ef-b742-2541213388e3|1  |NULL|2          |NULL|unqualified |NULL|NULL|NULL|NULL|NULL|41      |NULL|74    |NULL|43          |NULL|NULL|2024-09-14 17:08:47.907872|NULL|NULL|NULL|NULL        |NULL       |NULL      |NULL      |NULL    |NULL|NULL|\n",
      "|0d9e75b4-72bc-11ef-a21d-076f9f266266|0  |NULL|26         |NULL|click       |NULL|NULL|NULL|NULL|NULL|10      |NULL|125   |NULL|30          |NULL|NULL|2024-09-14 17:09:07.968238|NULL|NULL|NULL|NULL        |NULL       |NULL      |NULL      |NULL    |NULL|NULL|\n",
      "|1996c65a-72bc-11ef-9ddf-551fad6407e1|0  |NULL|46         |NULL|conversion  |NULL|NULL|NULL|NULL|NULL|41      |NULL|146   |NULL|37          |NULL|NULL|2024-09-14 17:09:28.050610|NULL|NULL|NULL|NULL        |NULL       |NULL      |NULL      |NULL    |NULL|NULL|\n",
      "|317f1fba-72bc-11ef-8823-0b4d0b9426a5|1  |NULL|47         |NULL|qualified   |NULL|NULL|NULL|NULL|NULL|29      |NULL|40    |NULL|22          |NULL|NULL|2024-09-14 17:10:08.160853|NULL|NULL|NULL|NULL        |NULL       |NULL      |NULL      |NULL    |NULL|NULL|\n",
      "|01ac1914-72bc-11ef-9764-6f23755be916|1  |NULL|6          |NULL|conversion  |NULL|NULL|NULL|NULL|NULL|31      |NULL|83    |NULL|47          |NULL|NULL|2024-09-14 17:08:47.924952|NULL|NULL|NULL|NULL        |NULL       |NULL      |NULL      |NULL    |NULL|NULL|\n",
      "|49618b0e-72bc-11ef-9e88-a3d22da78a6c|1  |NULL|28         |NULL|conversion  |NULL|NULL|NULL|NULL|NULL|9       |NULL|188   |NULL|22          |NULL|NULL|2024-09-14 17:10:48.232315|NULL|NULL|NULL|NULL        |NULL       |NULL      |NULL      |NULL    |NULL|NULL|\n",
      "|4964585c-72bc-11ef-a235-fab794bca5b1|0  |NULL|49         |NULL|unqualified |NULL|NULL|NULL|NULL|NULL|2       |NULL|25    |NULL|1           |NULL|NULL|2024-09-14 17:10:48.250689|NULL|NULL|NULL|NULL        |NULL       |NULL      |NULL      |NULL    |NULL|NULL|\n",
      "|f5bb65d8-72bb-11ef-a163-57c966313aef|1  |NULL|33         |NULL|conversion  |NULL|NULL|NULL|NULL|NULL|32      |NULL|116   |NULL|8           |NULL|NULL|2024-09-14 17:08:27.892573|NULL|NULL|NULL|NULL        |NULL       |NULL      |NULL      |NULL    |NULL|NULL|\n",
      "|31840822-72bc-11ef-ace2-a85347beb021|0  |NULL|4          |NULL|unqualified |NULL|NULL|NULL|NULL|NULL|33      |NULL|190   |NULL|19          |NULL|NULL|2024-09-14 17:10:08.193014|NULL|NULL|NULL|NULL        |NULL       |NULL      |NULL      |NULL    |NULL|NULL|\n",
      "|2587c702-72bc-11ef-a2fd-196106d5d0e6|0  |NULL|28         |NULL|unqualified |NULL|NULL|NULL|NULL|NULL|35      |NULL|33    |NULL|5           |NULL|NULL|2024-09-14 17:09:48.084902|NULL|NULL|NULL|NULL        |NULL       |NULL      |NULL      |NULL    |NULL|NULL|\n",
      "|317b9098-72bc-11ef-8ef4-b7668b84fc7f|1  |NULL|2          |NULL|unqualified |NULL|NULL|NULL|NULL|NULL|27      |NULL|99    |NULL|40          |NULL|NULL|2024-09-14 17:10:08.137555|NULL|NULL|NULL|NULL        |NULL       |NULL      |NULL      |NULL    |NULL|NULL|\n",
      "|01aea454-72bc-11ef-aa1d-26515cf10277|1  |NULL|31         |NULL|qualified   |NULL|NULL|NULL|NULL|NULL|31      |NULL|54    |NULL|26          |NULL|NULL|2024-09-14 17:08:47.941653|NULL|NULL|NULL|NULL        |NULL       |NULL      |NULL      |NULL    |NULL|NULL|\n",
      "|19948e26-72bc-11ef-86c2-d061f3c61534|1  |NULL|29         |NULL|unqualified |NULL|NULL|NULL|NULL|NULL|26      |NULL|49    |NULL|6           |NULL|NULL|2024-09-14 17:09:28.036051|NULL|NULL|NULL|NULL        |NULL       |NULL      |NULL      |NULL    |NULL|NULL|\n",
      "|f5bd2c42-72bb-11ef-bb15-359c15f3665d|0  |NULL|32         |NULL|qualified   |NULL|NULL|NULL|NULL|NULL|45      |NULL|7     |NULL|12          |NULL|NULL|2024-09-14 17:08:27.904197|NULL|NULL|NULL|NULL        |NULL       |NULL      |NULL      |NULL    |NULL|NULL|\n",
      "|1992f124-72bc-11ef-9d94-25d9417ea068|1  |NULL|30         |NULL|unqualified |NULL|NULL|NULL|NULL|NULL|39      |NULL|51    |NULL|22          |NULL|NULL|2024-09-14 17:09:28.025570|NULL|NULL|NULL|NULL        |NULL       |NULL      |NULL      |NULL    |NULL|NULL|\n",
      "|31801956-72bc-11ef-b0a5-f38cff6d7c72|1  |NULL|32         |NULL|unqualified |NULL|NULL|NULL|NULL|NULL|48      |NULL|185   |NULL|24          |NULL|NULL|2024-09-14 17:10:08.167245|NULL|NULL|NULL|NULL        |NULL       |NULL      |NULL      |NULL    |NULL|NULL|\n",
      "|3d72461c-72bc-11ef-b09e-8b4a128b753a|1  |NULL|16         |NULL|click       |NULL|NULL|NULL|NULL|NULL|40      |NULL|37    |NULL|15          |NULL|NULL|2024-09-14 17:10:28.209344|NULL|NULL|NULL|NULL        |NULL       |NULL      |NULL      |NULL    |NULL|NULL|\n",
      "|01af39d2-72bc-11ef-a058-2f11a78b7ba1|0  |NULL|37         |NULL|click       |NULL|NULL|NULL|NULL|NULL|3       |NULL|66    |NULL|4           |NULL|NULL|2024-09-14 17:08:47.945460|NULL|NULL|NULL|NULL        |NULL       |NULL      |NULL      |NULL    |NULL|NULL|\n",
      "|317d432a-72bc-11ef-a45a-eed8abf44b96|1  |NULL|38         |NULL|qualified   |NULL|NULL|NULL|NULL|NULL|42      |NULL|44    |NULL|31          |NULL|NULL|2024-09-14 17:10:08.148648|NULL|NULL|NULL|NULL        |NULL       |NULL      |NULL      |NULL    |NULL|NULL|\n",
      "+------------------------------------+---+----+-----------+----+------------+----+----+----+----+----+--------+----+------+----+------------+----+----+--------------------------+----+----+----+------------+-----------+----------+----------+--------+----+----+\n",
      "only showing top 20 rows\n",
      "\n",
      "None\n",
      "Filter out the data\n",
      "After Split:\n",
      "+-------------------+------+------------+---+-----------+--------+------------+\n",
      "|ts                 |job_id|custom_track|bid|campaign_id|group_id|publisher_id|\n",
      "+-------------------+------+------------+---+-----------+--------+------------+\n",
      "|2024-09-14 17:10:08|179   |conversion  |1  |38         |19      |21          |\n",
      "|2024-09-14 17:09:28|29    |unqualified |0  |29         |39      |38          |\n",
      "|2024-09-14 17:09:07|195   |qualified   |0  |41         |48      |40          |\n",
      "|2024-09-14 17:10:48|157   |click       |1  |31         |40      |20          |\n",
      "|2024-09-14 17:09:07|197   |conversion  |0  |40         |42      |10          |\n",
      "|2024-09-14 17:09:08|87    |unqualified |1  |13         |16      |20          |\n",
      "|2024-09-14 17:09:48|134   |conversion  |1  |16         |41      |43          |\n",
      "|2024-09-14 17:09:07|142   |conversion  |0  |4          |23      |19          |\n",
      "|2024-09-14 17:08:47|111   |click       |0  |36         |23      |34          |\n",
      "|2024-09-14 17:08:07|136   |qualified   |1  |32         |41      |37          |\n",
      "|2024-09-14 17:10:08|158   |qualified   |1  |35         |5       |13          |\n",
      "|2024-09-14 17:09:07|185   |unqualified |1  |33         |23      |19          |\n",
      "|2024-09-14 17:10:08|15    |qualified   |0  |11         |1       |1           |\n",
      "|2024-09-14 17:09:07|61    |qualified   |0  |25         |31      |13          |\n",
      "|2024-09-14 17:09:48|198   |conversion  |1  |29         |12      |28          |\n",
      "|2024-09-14 17:08:47|131   |unqualified |1  |37         |35      |38          |\n",
      "|2024-09-14 17:10:08|56    |conversion  |1  |45         |28      |3           |\n",
      "|2024-09-14 17:09:48|161   |qualified   |1  |47         |38      |47          |\n",
      "|2024-09-14 17:10:48|200   |click       |0  |38         |28      |38          |\n",
      "|2024-09-14 17:08:27|75    |unqualified |1  |32         |43      |30          |\n",
      "+-------------------+------+------------+---+-----------+--------+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/09/14 17:45:37 WARN V2ScanPartitioningAndOrdering: Spark ignores the partitioning CassandraPartitioning. Please use KeyGroupedPartitioning for better performance\n",
      "24/09/14 17:45:38 WARN V2ScanPartitioningAndOrdering: Spark ignores the partitioning CassandraPartitioning. Please use KeyGroupedPartitioning for better performance\n",
      "24/09/14 17:45:38 WARN V2ScanPartitioningAndOrdering: Spark ignores the partitioning CassandraPartitioning. Please use KeyGroupedPartitioning for better performance\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+------+------------+---+-----------+--------+------------+\n",
      "|ts                 |job_id|custom_track|bid|campaign_id|group_id|publisher_id|\n",
      "+-------------------+------+------------+---+-----------+--------+------------+\n",
      "|2024-09-14 17:09:08|28    |qualified   |0.0|47         |33      |11          |\n",
      "|2024-09-14 17:08:27|108   |conversion  |0.0|39         |43      |4           |\n",
      "|2024-09-14 17:10:28|81    |qualified   |0.0|6          |27      |6           |\n",
      "|2024-09-14 17:08:07|135   |click       |1.0|17         |30      |49          |\n",
      "|2024-09-14 17:10:48|22    |unqualified |1.0|39         |6       |42          |\n",
      "|2024-09-14 17:08:47|175   |unqualified |1.0|48         |14      |8           |\n",
      "|2024-09-14 17:10:08|154   |unqualified |1.0|45         |27      |8           |\n",
      "|2024-09-14 17:09:07|9     |unqualified |1.0|6          |5       |33          |\n",
      "|2024-09-14 17:09:08|122   |conversion  |0.0|11         |48      |36          |\n",
      "|2024-09-14 17:08:47|54    |qualified   |1.0|31         |31      |26          |\n",
      "|2024-09-14 17:09:28|49    |unqualified |1.0|29         |26      |6           |\n",
      "|2024-09-14 17:08:27|7     |qualified   |0.0|32         |45      |12          |\n",
      "|2024-09-14 17:09:28|51    |unqualified |1.0|30         |39      |22          |\n",
      "|2024-09-14 17:10:08|185   |unqualified |1.0|32         |48      |24          |\n",
      "|2024-09-14 17:10:28|37    |click       |1.0|16         |40      |15          |\n",
      "|2024-09-14 17:08:47|66    |click       |0.0|37         |3       |4           |\n",
      "|2024-09-14 17:10:08|44    |qualified   |1.0|38         |42      |31          |\n",
      "|2024-09-14 17:09:07|47    |unqualified |0.0|29         |49      |1           |\n",
      "|2024-09-14 17:09:48|126   |qualified   |1.0|48         |1       |5           |\n",
      "|2024-09-14 17:10:08|48    |qualified   |1.0|23         |43      |8           |\n",
      "+-------------------+------+------------+---+-----------+--------+------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "None\n",
      "+-------------------+------+------------+---+-----------+--------+------------+\n",
      "|ts                 |job_id|custom_track|bid|campaign_id|group_id|publisher_id|\n",
      "+-------------------+------+------------+---+-----------+--------+------------+\n",
      "|2024-09-14 17:09:28|169   |unqualified |1.0|6          |33      |12          |\n",
      "|2024-09-14 17:08:47|164   |qualified   |1.0|40         |29      |36          |\n",
      "|2024-09-14 17:10:08|182   |conversion  |0.0|13         |37      |40          |\n",
      "|2024-09-14 17:09:48|190   |click       |0.0|46         |5       |22          |\n",
      "|2024-09-14 17:10:48|31    |conversion  |0.0|36         |30      |43          |\n",
      "|2024-09-14 17:09:48|13    |conversion  |1.0|13         |7       |15          |\n",
      "|2024-09-14 17:08:07|121   |click       |1.0|39         |19      |37          |\n",
      "|2024-09-14 17:09:08|28    |qualified   |0.0|47         |33      |11          |\n",
      "|2024-09-14 17:08:27|108   |conversion  |0.0|39         |43      |4           |\n",
      "|2024-09-14 17:10:28|81    |qualified   |0.0|6          |27      |6           |\n",
      "|2024-09-14 17:08:07|135   |click       |1.0|17         |30      |49          |\n",
      "|2024-09-14 17:10:48|22    |unqualified |1.0|39         |6       |42          |\n",
      "|2024-09-14 17:08:47|175   |unqualified |1.0|48         |14      |8           |\n",
      "|2024-09-14 17:10:08|154   |unqualified |1.0|45         |27      |8           |\n",
      "|2024-09-14 17:09:07|9     |unqualified |1.0|6          |5       |33          |\n",
      "|2024-09-14 17:09:08|122   |conversion  |0.0|11         |48      |36          |\n",
      "|2024-09-14 17:09:08|198   |conversion  |0.0|45         |15      |1           |\n",
      "|2024-09-14 17:08:07|103   |qualified   |1.0|2          |47      |11          |\n",
      "|2024-09-14 17:09:07|164   |conversion  |1.0|9          |33      |12          |\n",
      "|2024-09-14 17:09:48|14    |qualified   |1.0|24         |42      |9           |\n",
      "+-------------------+------+------------+---+-----------+--------+------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "None\n",
      "Process the data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/09/14 17:45:38 WARN V2ScanPartitioningAndOrdering: Spark ignores the partitioning CassandraPartitioning. Please use KeyGroupedPartitioning for better performance\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get company data from mysql\n",
      "Merge the data with company data\n",
      "finalizing the data\n",
      "final ouput\n",
      "+------+----------+-----+------------------------+---------------------+----------+----------+--------+-----------+------------+-------+------+----------+---------+-------------------+\n",
      "|job_id|     dates|hours|disqualified_application|qualified_application|conversion|company_id|group_id|campaign_id|publisher_id|bid_set|clicks|spend_hour|  sources|         updated_at|\n",
      "+------+----------+-----+------------------------+---------------------+----------+----------+--------+-----------+------------+-------+------+----------+---------+-------------------+\n",
      "|   103|2024-09-14|   17|                    NULL|                    1|      NULL|         1|      47|          2|          11|   NULL|  NULL|      NULL|Cassandra|2024-09-14 17:10:48|\n",
      "|   106|2024-09-14|   17|                       1|                 NULL|      NULL|         1|      22|         37|          47|   NULL|  NULL|      NULL|Cassandra|2024-09-14 17:10:48|\n",
      "|   107|2024-09-14|   17|                    NULL|                 NULL|      NULL|         1|      31|          7|          29|    1.0|     1|       1.0|Cassandra|2024-09-14 17:10:48|\n",
      "|   108|2024-09-14|   17|                    NULL|                 NULL|         1|         1|      43|         39|           4|   NULL|  NULL|      NULL|Cassandra|2024-09-14 17:10:48|\n",
      "|   111|2024-09-14|   17|                    NULL|                 NULL|      NULL|         1|      23|         36|          34|    0.0|     1|       0.0|Cassandra|2024-09-14 17:10:48|\n",
      "|   113|2024-09-14|   17|                       1|                 NULL|      NULL|         1|      23|         11|          20|   NULL|  NULL|      NULL|Cassandra|2024-09-14 17:10:48|\n",
      "|   114|2024-09-14|   17|                    NULL|                 NULL|         1|         1|      34|         21|          44|   NULL|  NULL|      NULL|Cassandra|2024-09-14 17:10:48|\n",
      "|   116|2024-09-14|   17|                    NULL|                 NULL|         1|         1|      32|         33|           8|   NULL|  NULL|      NULL|Cassandra|2024-09-14 17:10:48|\n",
      "|   117|2024-09-14|   17|                    NULL|                 NULL|         1|         1|      16|         13|           9|   NULL|  NULL|      NULL|Cassandra|2024-09-14 17:10:48|\n",
      "|   119|2024-09-14|   17|                    NULL|                 NULL|      NULL|         1|      45|         43|           1|    0.0|     1|       0.0|Cassandra|2024-09-14 17:10:48|\n",
      "|   121|2024-09-14|   17|                    NULL|                 NULL|      NULL|         1|      19|         39|          37|    1.0|     1|       1.0|Cassandra|2024-09-14 17:10:48|\n",
      "|   122|2024-09-14|   17|                       1|                 NULL|      NULL|         1|      36|          5|          24|   NULL|  NULL|      NULL|Cassandra|2024-09-14 17:10:48|\n",
      "|   122|2024-09-14|   17|                    NULL|                 NULL|         1|         1|      48|         11|          36|   NULL|  NULL|      NULL|Cassandra|2024-09-14 17:10:48|\n",
      "|   123|2024-09-14|   17|                    NULL|                 NULL|         1|         1|      43|          4|          22|   NULL|  NULL|      NULL|Cassandra|2024-09-14 17:10:48|\n",
      "|   124|2024-09-14|   17|                    NULL|                    1|      NULL|         1|      45|         18|          17|   NULL|  NULL|      NULL|Cassandra|2024-09-14 17:10:48|\n",
      "|   125|2024-09-14|   17|                    NULL|                 NULL|      NULL|         1|      10|         26|          30|    0.0|     1|       0.0|Cassandra|2024-09-14 17:10:48|\n",
      "|   126|2024-09-14|   17|                    NULL|                    1|      NULL|         1|       1|         48|           5|   NULL|  NULL|      NULL|Cassandra|2024-09-14 17:10:48|\n",
      "|   128|2024-09-14|   17|                    NULL|                 NULL|         1|         1|      16|         30|          15|   NULL|  NULL|      NULL|Cassandra|2024-09-14 17:10:48|\n",
      "|    13|2024-09-14|   17|                    NULL|                 NULL|         1|      NULL|       7|         13|          15|   NULL|  NULL|      NULL|Cassandra|2024-09-14 17:10:48|\n",
      "|   130|2024-09-14|   17|                    NULL|                 NULL|      NULL|         1|      34|         28|          11|    0.0|     1|       0.0|Cassandra|2024-09-14 17:10:48|\n",
      "+------+----------+-----+------------------------+---------------------+----------+----------+--------+-----------+------------+-------+------+----------+---------+-------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "None\n",
      "Job takes 1.929036 seconds to execute\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[75], line 37\u001b[0m\n\u001b[1;32m     35\u001b[0m execution_time \u001b[38;5;241m=\u001b[39m (end_time \u001b[38;5;241m-\u001b[39m start_time)\u001b[38;5;241m.\u001b[39mtotal_seconds()\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mJob takes \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m seconds to execute\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(execution_time))\n\u001b[0;32m---> 37\u001b[0m \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m60\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def get_latest_time_cassandra():\n",
    "    data = spark.read.format(\"org.apache.spark.sql.cassandra\").options(table = 'tracking',keyspace = 'my_keyspace').load()\n",
    "    cassandra_latest_time = data.agg({'ts':'max'}).take(1)[0][0]\n",
    "    return cassandra_latest_time\n",
    "\n",
    "def get_mysql_latest_time(host,port,db_name,driver,user,password):    \n",
    "    sql_query = \"\"\"(select max(updated_at) from events) data\"\"\"\n",
    "    mysql_time = get_data_from_mysql(host,port,db_name,driver,user,password,sql_query)\n",
    "    mysql_time = mysql_time.take(1)[0][0]\n",
    "    if mysql_time is None:\n",
    "        mysql_latest_time = '1970-01-01 23:59:59'\n",
    "    else:\n",
    "        mysql_latest_time = mysql_time.strftime('%Y-%m-%d %H:%M:%S')\n",
    "    return mysql_latest_time \n",
    "while True:\n",
    "    start_time = datetime.datetime.now()\n",
    "    cassandra_latest_time = get_latest_time_cassandra()\n",
    "    mysql_latest_time = get_mysql_latest_time(host,port,db_name,driver,user,password)\n",
    "\n",
    "    mysql_latest_time = datetime.datetime.strptime(mysql_latest_time, '%Y-%m-%d %H:%M:%S')\n",
    "    if '.' in cassandra_latest_time:\n",
    "        cassandra_latest_time = cassandra_latest_time.split('.')[0]\n",
    "    cassandra_latest_time = datetime.datetime.strptime(cassandra_latest_time, '%Y-%m-%d %H:%M:%S')\n",
    "           \n",
    "    print(f'{type(cassandra_latest_time)} :  {cassandra_latest_time}')\n",
    "    print(f'{type(mysql_latest_time)} :  {mysql_latest_time}')\n",
    "    \n",
    "    if cassandra_latest_time > mysql_latest_time:\n",
    "        print(f\"bruh cassandra_latest_time: {cassandra_latest_time} > mysql_latest_time: {mysql_latest_time}\")\n",
    "        main_task(cassandra_latest_time,mysql_latest_time)\n",
    "    else:\n",
    "        print(\"No new data found in cassandra\")\n",
    "    \n",
    "    end_time = datetime.datetime.now()\n",
    "    execution_time = (end_time - start_time).total_seconds()\n",
    "    print('Job takes {} seconds to execute'.format(execution_time))\n",
    "    time.sleep(60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+\n",
      "|ts                 |\n",
      "+-------------------+\n",
      "|2022-07-26 03:07:17|\n",
      "+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_df = spark.createDataFrame([(\"2022-07-26 03:07:17.315\",)], [\"ts\"])\n",
    "test_df = test_df.withColumn(\"ts\", sf.split(col(\"ts\"), \"\\\\.\").getItem(0))\n",
    "test_df.show(truncate=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
